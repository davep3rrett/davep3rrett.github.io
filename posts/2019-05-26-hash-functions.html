<!doctype html>
<html>
<head>
  <title>Dave Perrett Details His Computing Misadventures </title>
  <link rel="stylesheet" type="text/css" href="../main.min.css">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
  <meta name="description" content="Dave Perrett Details His Computing Misadventures - A Programming Blog. Dave Perrett is a developer and musician living in Brooklyn, NY.">
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <link rel="icon" href="favicon.ico" type="image/x-icon">
</head>

<body>
  <header>
    <a href="../index.html"><h1>Dave Perrett Details His Computing Misadventures</h1></a>
  </header>
  <div class="main-content">



<h2 id="reading-about-hash-functions">Reading about hash functions</h2>
<p>I&#39;ve finally started to feel ready to follow up on one of the promises in <a href="2018-08-16-c-hashtable-vim-preamble.html">this post</a> and get going with my project of implementing a hashtable data structure from scratch.</p>
<p>As I had gleaned earlier from my initial searches on the topic, a really important part of a hashmap is having a good <strong><em>hash function</em></strong>.</p>
<p>There&#39;s an important distinction between cryptographic hash functions used for encryption / privacy / security etc. and the noncryptographic hash functions used in hashtables. Their goals are different.</p>
<p>One of the main requirements of a hash function used in a hashtable is for it to have a <em>uniform distribution</em> of hash values. Since you ideally want collisions (multiple inputs hashing to the same value) to be low or non-existent, having as close to a uniform distribution as possible is really important so certain inputs won&#39;t have a higher likelihood of colliding than others.</p>
<p>A common strategy for dealing with collisions is to keep a linked list at the slot of a particular hash value, which contains all keys that hash to that value. It is therefore in the interest of performance for the linked lists to be kept short.</p>
<h3 id="who-s-who-in-the-world-of-hash-functions">Who&#39;s who in the world of hash functions</h3>
<p>When I started I didn&#39;t know anything about hash functions, and articles I would read about hashtables would say things like &quot;It&#39;s important to choose a good hash function.&quot; and then move on.</p>
<p>Who&#39;s coming up with these hash functions?! Are they all figured out and canonically listed out in a textbook somewhere? What&#39;s the deal?</p>
<p>After further searching I found <a href="http://www.azillionmonkeys.com/qed/hash.html">this hash function</a> by Paul Hsieh linked in <a href="https://stackoverflow.com/a/746727">this SO answer</a>.</p>
<p>In Paul&#39;s notes about benchmarking performed for his hash function, I saw the name <a href="https://burtleburtle.net/bob/">Bob Jenkins</a> come up a couple times. It seems he is &quot;the guy&quot; in this particular field, and has himself created a set of widely used noncryptographic hash functions called <a href="https://burtleburtle.net/bob/c/lookup3.c">lookup3</a>.</p>
<p>An interesting takeaway is that the field of hash functions seems to be a somewhat living field, where discoveries are still sometimes made, like prime number research or something. This contradicts the notion I held going in, that hash functions are a &quot;solved&quot; computer science problem immortalized in textbooks.</p>
<h3 id="why-was-it-so-hard-for-me-to-find-out-about-this-">Why was it so hard for me to find out about this?</h3>
<p>I may have just been searching wrong, but it really took me a while to find information about specific hash functions, how they are created, and who creates them. I found an interesting albeit slightly paranoid blog post, which supported my feeling of <em>&quot;Why does it seem like this stuff is intentionally being kept secret?&quot;</em> on a bioinformatics blog, titled <a href="https://homolog.us/blogs/bioinfo/2013/05/06/why-computer-science-professors-dislike-hash-functions/">Why Computer Science Professors Dislike Hash Functions</a>. I won&#39;t try to paraphrase the arguments here, but check it out if you&#39;re interested.</p>
<h3 id="next-steps">Next steps</h3>
<p>The reason I started searching for specifics on hash functions in the first place is that I was hoping to find a relatively simple &quot;beginner&quot; hash function - maybe in pseudocode so I could implement myself in C, or just finding something written in C would be fine too.</p>
<p>Both Hsieh&#39;s SuperFastHash and Bob Jenkins&#39; hashes are much more complicated than what I was ready for. However, on Jenkins&#39; site, in his <a href="https://burtleburtle.net/bob/hash/index.html#lookup">discussion of hash functions for hash table lookup</a>, he provides the following:</p>
<blockquote>
<p>The standard reference for this is Knuth&#39;s &quot;The Art of Computer Programming&quot;, volume 3 &quot;Sorting and Searching&quot;, chapter 6.4. He recommends the hash</p>
</blockquote>
<pre><code>for (hash=len; len--;)
   {
     hash = ((hash&lt;&lt;5)^(hash&gt;&gt;27))^*key++;
   }
   hash = hash % prime;</code></pre><p>This is the &quot;rotating hash&quot;, which gets elucidated further in Bob&#39;s other writings:</p>
<pre><code>ub4 rotating(char *key, ub4 len, ub4 prime)
{
  ub4 hash, i;
  for (hash=len, i=0; i&lt;len; ++i)
    hash = (hash&lt;&lt;4)^(hash&gt;&gt;28)^key[i];
  return (hash % prime);
}</code></pre><blockquote>
<p>This takes 8n+3 instructions. This is the same as the additive hash, except it has a mixing step (a circular shift by 4) and the combining step is exclusive-or instead of addition. The table size is a prime, but the prime can be any size.</p>
</blockquote>
<blockquote>
<p>On machines with a rotate (such as the Intel x86 line) this is 6n+2 instructions. I have seen the <code>(hash % prime)</code> replaced with</p>
</blockquote>
<pre><code>hash = (hash ^ (hash&gt;&gt;10) ^ (hash&gt;&gt;20)) &amp; mask;</code></pre><blockquote>
<p>eliminating the % and allowing the table size to be a power of 2, making this 6n+6 instructions. % can be very slow, for example it is 230 times slower than addition on a Sparc 20. </p>
</blockquote>
<p>Also, here is a more in-depth article on hash functions written by Bob Jenkins: <a href="https://burtleburtle.net/bob/hash/doobs.html">https://burtleburtle.net/bob/hash/doobs.html</a>.</p>
<p>This level of analysis, math, and facility with machine instructions is all pretty over my head, but at any rate the Knuth stuff feels like a logical starting point / reference for a relatively simple hash function, although Bob warns that the rotating hash only provides &quot;mediocre&quot; results. I would probably want to use a more modern hash function in a production / &quot;real world&quot; use case, but at this point I&#39;m still just trying to figure out what the heck is going on.</p>
<h3 id="update-2019-05-27">Update 2019-05-27</h3>
<p>I went to check out The Art of Computer Proramming Vol. 3 - which I have admittedly not delved into before - to try and gain some context on the code snippet above. I didn&#39;t realize that all of Knuth&#39;s code samples are written in <a href="https://en.wikipedia.org/wiki/MIX">MIX</a> Assembly, an assembly language for a hypothetical computer that he invented. So that&#39;s going to take some brushing up on my part &#x1F605;</p>
<p>But I found <a href="https://stackoverflow.com/questions/11871245/knuth-multiplicative-hash">this explainer</a> on SO of the multiplicative hash that is also outlined in chapter 6.4, and decided to take that function for a spin.</p>
<p>I also took the time to initialize my Git repo that will ultimately house my hashtable project. You can find it hosted <a href="https://git.sr.ht/~davep3rrett/hash-table">here</a> on the very cool <a href="https://sourcehut.org/">Sourcehut</a>, which I will maybe write more about my experience with in future posts!</p>



</div>
<footer>
  <hr>
  <p>&copy; 2019 Dave Perrett</p>
</footer>
</body>
</html>



